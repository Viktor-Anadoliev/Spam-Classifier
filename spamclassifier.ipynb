{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classifier\n",
    "\n",
    "This is a NaÃ¯ve Bayes supervised learning based classifier to suggest whether a given email is spam or ham(not spam).\n",
    "\n",
    "## Training Data\n",
    "The training data is shown below and has 1000 rows including test data of 500 rows. Test data is functionally identical to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML,Javascript, display\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(int)\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(training_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set consists of 1000 rows and 55 columns. Each row corresponds to one email message. The first column is the _response_ variable and describes whether a message is spam `1` or not `0`. The remaining 54 columns are _features_ that are used to build a classifier. These features correspond to 54 different keywords (such as \"money\", \"free\", and \"receive\") and special characters (such as \":\", \"!\", and \"$\"). A feature has the value `1` if the keyword appears in the message and `0` otherwise.\n",
    "\n",
    "As mentioned there is also a 500 row set of *test data*. It contains the same 55 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam testing data set: (500, 55)\n",
      "[[1 0 0 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "print(testing_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier takes input data and returns class predictions. The input is a single $n \\times 54$ numpy array, the classifier returns a numpy array of length $n$ with classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def estimate_log_class_priors(self, data):\n",
    "        # extracting the class labels\n",
    "        class_labels = data[:, 0]\n",
    "\n",
    "        # counting the occurences of 0s and 1s in the left-most column\n",
    "        count_0s = np.sum(class_labels == 0)\n",
    "        count_1s = np.sum(class_labels == 1)\n",
    "\n",
    "        # finding the number of samples\n",
    "        n_samples = len(class_labels)\n",
    "\n",
    "        # calculating the logarithms of the empirical class priors (0s and 1s)\n",
    "        log_prob_c0 = np.log(count_0s / n_samples)\n",
    "        log_prob_c1 = np.log(count_1s / n_samples)\n",
    "\n",
    "        return np.array([log_prob_c0, log_prob_c1])\n",
    "\n",
    "    def estimate_log_class_conditional_likelihoods(self, data, alpha=1.0):\n",
    "        # find and seperate spam and ham messages in different arrays\n",
    "        ham_data = data[data[:, 0] == 0][:, 1:]\n",
    "        spam_data = data[data[:, 0] == 1][:, 1:]\n",
    "        #Include k? not self.k?\n",
    "        #k = data.shape[1] - 1\n",
    "\n",
    "        # counting the occurences of spam and ham messages\n",
    "        count_hams = len(ham_data)\n",
    "        count_spams = len(spam_data)\n",
    "\n",
    "        # calculate the number of times that each feature(word) appears in spam and ham messages\n",
    "        n_of_words_ham = ham_data.sum(axis=0)\n",
    "        n_of_words_spam = spam_data.sum(axis=0)\n",
    "\n",
    "        # calculating total number of words in spam and ham messages\n",
    "        total_n_of_words_ham = n_of_words_ham.sum()\n",
    "        total_n_of_words_spam = n_of_words_spam.sum()\n",
    "\n",
    "        theta_ham = []\n",
    "        for i in range(0, n_of_words_ham.shape[0]):\n",
    "            theta_ham.append(np.log((n_of_words_ham[i] + alpha)/(total_n_of_words_ham + self.k*alpha)))\n",
    "\n",
    "        theta_spam = []\n",
    "        for i in range(0, n_of_words_spam.shape[0]):\n",
    "            theta_spam.append(np.log((n_of_words_spam[i] + alpha)/(total_n_of_words_spam + self.k*alpha)))\n",
    "\n",
    "        theta = np.array([theta_ham, theta_spam])\n",
    "        return theta\n",
    "        \n",
    "    def train(self):\n",
    "        self.log_class_priors = self.estimate_log_class_priors(training_spam)\n",
    "        self.log_class_conditional_likelihoods = self.estimate_log_class_conditional_likelihoods(training_spam, alpha=1.0)\n",
    "        \n",
    "    def predict(self, new_data):\n",
    "        # finding the sum of the ham conditional likehoods multiplied by the words binary value in the new data (0 if not present)\n",
    "        ham_likelihoods_sum = np.dot(new_data[:,:], self.log_class_conditional_likelihoods[0])\n",
    "        # finding the numerator of probability that the message is ham\n",
    "        ham_results = self.log_class_priors[0] + ham_likelihoods_sum\n",
    "\n",
    "        # finding the sum of the spam conditional likehoods multiplied by the words binary value in the new data (0 if not present)\n",
    "        spam_likelihoods_sum = np.dot(new_data[:,:], self.log_class_conditional_likelihoods[1])\n",
    "        # finding the numerator of probability that the message is spam\n",
    "        spam_results = self.log_class_priors[1] + spam_likelihoods_sum\n",
    "\n",
    "        # calculating the maximum a posteriori estimate for each row(each message) and finding the results\n",
    "        class_predictions_ls = []\n",
    "        for i in range (0, new_data.shape[0]):\n",
    "            if ham_results[i] >= spam_results[i]:\n",
    "                class_predictions_ls.append(0)\n",
    "            else:\n",
    "                class_predictions_ls.append(1)\n",
    "        \n",
    "        # changing the type from list to np.array\n",
    "        class_predictions = np.array(class_predictions_ls)\n",
    "        return class_predictions\n",
    "\n",
    "    \n",
    "def create_classifier():\n",
    "    classifier = SpamClassifier(k=54)\n",
    "    classifier.train()\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
